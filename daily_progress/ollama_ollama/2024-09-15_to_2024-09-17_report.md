# ollama 项目进展

## 时间周期：2024-09-15至2024-09-17

## 新增功能
- 添加了 `vim-intelligence-bridge` 到 README 的 Terminal 部分。
- 创建了 `docker-image.yml` 用于更好的构建和部署。

## 主要改进
- 更新了 CI 配置，清理了命名，并修正了最新标签的处理。
- 确保平台构建脚本 `build_linux`能正常工作，兼容 `buildx`。
- 清理 KV 缓存，在驱逐槽位时清除旧的 KV 缓存条目。
- 支持在无 AVX 的老旧 CPU 上使用 GPU。

## 修复问题
- 修复了 `使用Modelfile加载本地gguf文件，会胡乱输出内容` 的问题。
- 修正了 Gemma 2 模型卡中的拼写错误。
- 解决了高 GPU 和 CPU 使用率的问题。
- 优化了处理大量带中文标点的文本时的意外中断问题。
- 修复了多起与 Llama 和 Ollama 运行相关的错误，包括内存分配失败和模型加载问题。
- 解决了 `ollama run deepseek-coder-v2` 产生杂乱输出的错误。
- 修复了与环境变量有关的问题，确保模型的并发处理。

通过这些更新，ollama 项目正在不断完善，为用户提供更稳定和功能丰富的使用体验。